% !Mode:: "TeX:UTF-8"

\chapter{基于CD-Phone和CTC的语音识别}

无论是经典的HMM-GMM识别系统，还是基于HMM-DL的识别系统，均属于HMM的识别框架。
RNN的强大的时序序列建模能力在一定程度上可以学习HMM框架中的状态变化和跳转，
因此识别任务中RNN的引入，逐步淡化了HMM框架的作用。
HMM框架经过几十年的发展，已经非常的完善，
深度学习引入识别任务后，
识别系统的结构进一步复杂，进行识别任务所需的步骤流程也越来越长。

因此，如何打破HMM框架，简化识别系统的流程，
进一步挖掘深度学习在语音识别任务上的能力成为目前语音识别研究的新热点之一\ucite{hannun2014deep, amodei2015deep, miao2015eesen}。
基于CD-Phone和CTC的语音识别是这些研究中的典型代表。
Phone和CD-Phone建模打破了经典的基于HMM状态CD-State建模的方法；
CTC的end-to-end的建模能力可以使基于深度学习的语音识别系统无需依赖经典的HMM-GMM框架，可以大幅度简化现有识别系统的流程。

本章分别介绍基于CD-Phone和CTC的语音识别，及其在声学建模中的应用。

\section{CD-Phone}

\subsection{传统建模单元CD-State} \label{seg:cdstate}

状态是HMM的基本建模单元，基于HMM的语音识别系统中每个音素Phone一般使用3状态的HMM。
在一般的语音识别系统中，音素的个数一般为几十个至上百个，例如TIMIT中音素数目为48，
汉语的语料库中即使带调的音素也不超过200。所以建模的单元数量少，建模不够精细。
为了对音素进行精确建模，可以进一步考虑音素所处的上下文，一般考虑音素所处位置的
前一个音素和后一个音素。例如对于音素b，我们可以建立a-b+c的三音素模型，其中a表示b
左边的音素，c表示b右边的音素。假设共有$N$个音素，考虑所有的上下文，一共可以得到$N^3$个三音素，
这样就解决了建模单元不够多，建模不够精细的问题。

然而，这样引进了新的问题。第一，建模单元太多，在训练数据固定的情况下，每个建模单元得到的训练数据不够充分；
第二，有一些三音素可能未在训练数据中出现，例如在汉语语料中，一般不会出现连续三个辅音的三音素，例如b-b+b,
z-z+z等。

\subsubsection{状态绑定}

在经典的语音识别系统中，使用决策树和状态绑定（Tied-State）来解决这个问题。
状态绑定是指对于一个单音素的任意一个状态，该状态的一些三音素可以共享一个概率密度分布，即共享一个状态号，
例如a-b+a，e-b+a，i-b+a，o-b+a可以共享一个状态，因为他们的左上文\{a, e, i, o\}均为元音，
很可能在发音上具有相近性。通过状态绑定，一些发音相近的三音素状态可以共享相同的训练数据，
训练数据中未出现的三音素状态也可以绑定到已经出现的三音素上状态上，
这样即解决了训练数据稀疏和未出现三音素状态的建模问题。
最终，将决策树和状态绑定形成的三音素状态称为CD-State（Context Dependent State），以表明基本的聚类单元是状态，
并且状态是上下文相关的。

\begin{figure}[htbp]
\centering
\includegraphics[width=1.0\textwidth]{figures/chapter4/cdstate-crop}
\caption{CD-State构建过程}
\label{fig:cdstate}
\end{figure}

HMM系统中CD-Stae的建立过程如图\ref{fig:cdstate}所示，流程如下
    \begin{enumerate}
        \item 首先建立和训练三状态的单音素的HMM模型。
        \item 使用已有单音素或三音素的模型得到三音素对齐，通过决策树建立状态绑定的三音素模型，迭代训练该模型。
        \item 重复2，直至模型训练充分。
    \end{enumerate}

\subsubsection{决策树}

上文提到建立CD-State的基本方法是决策树聚类。决策树是一个二叉树，在每个节点上都有相应的问题。
该问题相当于一个位置信息和一个音素集合，表示在当前层次，这个集合中的音素发音具有相近性。
对于三音素a-b+c，决策树会首先查看该节点的位置信息，通过位置信息确定是要判断b左边的音素还是右边的音素，
确定之后，然后判断该音素是否在该节点的音素集合中，若找到，
则走该节点的左子树，反之则走右子树。决策树的叶子节点表示最终三音素状态绑定的结果，
即该节点上的三音素共享相同的状态号。
对于任意一个三音素的给定HMM状态，通过该决策树就能查找到其最终的聚类结果。

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/chapter4/tree-crop}
\caption{决策树示例}
\label{fig:tree}
\end{figure}

一个决策树的示例如图\ref{fig:tree}所示。根节点表示单音素，第二层表示单音素的三个状态，
第三层及其一下表示决策树状态决策过程。例如，对于三音素a-b+c的第二个状态，首先查找到状态2；
状态2上会看b的左边的音素是否在集合\{a, b, c, d, e\}中，判断为是，走到状态4；
接着判断a+b-c的右边状态是否在集合\{a, e\}中，判断为否，转到状态6；
状态6已经是叶子节点，查找结束。6即是三音素a-b+c的第二个HMM状态的聚类结果。

那么该决策树又是如何构建的呢？决策树是一个自上而下逐步构建的过程\ucite{young1994tree}。
首先，在单音素HMM状态的根节点上，所有的状态都被假设归位一类，然后计算其似然；
假设训练数据集为$S = ({x_1},...,{x_M}) \in ({R^N})$，其中$M$表示特征样本总数，$N$表示特征维度，
且各维特征相互独立（HMM-GMM系统中使用MFCC特征，使用对角高斯描述），则对于特征$\textbf{x}$，其似然为：
\begin{equation}
[P(x) = \frac{1}{{\prod\nolimits_{k = 1}^N {{{(2\pi \sigma _k^2)}^{1/2}}} }}\prod\limits_{k = 1}^N {\exp ( - \frac{1}{2}} \frac{{{{({x_k} - {\mu _k})}^2}}}{{\sigma _k^2}})
\end{equation}
对于集合$S$，其log似然为：
\begin{equation}
\begin{array}{l}
L(S) =  - \frac{1}{2}\sum\limits_{i = 1}^M {\left[ {\sum\limits_{k = 1}^N {\log (2\pi \sigma _k^2)}  + \sum\limits_{k = 1}^N {\frac{{{{({x_{ik}} - {\mu _k})}^2}}}{{\sigma _k^2}}} } \right]} \\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  =  - \frac{1}{2}\left[ {M\sum\limits_{k = 1}^N {\log (2\pi \sigma _k^2) + M} \sum\limits_{k = 1}^N {\frac{{\sigma _k^2}}{{\sigma _k^2}}} } \right]\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  =  - \frac{1}{2}\left[ {MN(1 + \log (2\pi ) + M\sum\limits_{k = 1}^N {\log (\sigma _k^2)} } \right]
\end{array}
\end{equation}
其中$\mu _k$表示集合$S$第$k$维的均值，$\sigma _k^2$表示集合$S$第$k$维的方差。
然后通过问题集中的一个问题将该节点分为两部分$S_l$和$S_r$，分别计算这两部分的似然和；
\begin{equation}
L({S_l}) + L({S_r}) =  - \frac{1}{2}\left[ {MN(1 + \log (2\pi ) + {M_l}\sum\limits_{k = 1}^N {\log (\sigma _{lk}^2) + {M_r}\sum\limits_{k = 1}^N {\log (\sigma _{rk}^2)} } } \right]
\end{equation}
遍历所有的问题集，选出似然增益和最大的问题作为最优问题；
\begin{equation}
\begin{array}{l}
{q^*} = \mathop {\arg \min }\limits_q L({S_{lq}}) + L({S_{rq}}) - L(S)\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  = \mathop {\arg \min }\limits_q \left[ {{M_l}\sum\limits_{k = 1}^N {\log (\sigma _{lk}^2) + {M_r}\sum\limits_{k = 1}^N {\log (\sigma _{rk}^2)} } } \right]
\end{array}
\end{equation}
其中$q^*$表示最优问题，并将根节点分为两部分。
然后递归的对所有分裂出来的新节点执行上述算法，
终止条件一般为，第一，每个节点上的在训练数据中的统计量已在小于设定临界值（避免该状态没有得到充分的训练数据）；
第二，似然增益已小于设定阈值（该状态上所有绑定的三音素已足够相近）； 两个条件满足其一即可。

\subsubsection{问题集}

在构建决策树时需要使用问题集，一个问题由一组声学上相近的音素组成，多个问题形成的集合即为问题集。
问题集的构建有两种方式：
\begin{enumerate}
\item 人工设计，根据语音和语言学的知识进行设计，与特定语言和任务相关，例如HTK\ucite{young2002htk}中即使用这种问题集。
\item 自动生成问题集，根据训练数据中的单音素对齐得到各个音素的发音特征，然后进行树聚类得到问题集。
\end{enumerate}
Kaldi\ucite{povey2011kaldi}中既可以使用人工设计的问题集，同时也能自动生成问题集，也可以两者结合使用。

\subsection{Phone和CD-Phone建模单元}

HMM建模的一个前提假设是状态的独立假设。在GMM和DNN中，当前时刻的状态预测仅与当前时刻的输出特征相关，
而在RNN中，因为RNN的内部状态，当前时刻预测输出不仅与当前时刻相关，而且还依赖历史时刻的输入。
所以，这一前提假设已经不成立，而且RNN强大的时序建模能力已经能够拟合HMM所描述的状态变化和跳转过程。
所以，直接使用Phone进行建模，使用RNN表述Phone的变化过程成为一种新思路。

使用Phone作为建模单元的过程如下：
\begin{enumerate}
\item 通过HMM-GMM系统得到状态对齐，进一步得到Phone对齐；
\item 直接Phone对齐训练基于Phone的RNN的声学模型。
\end{enumerate}
在解码时，HMM中的三状态约束使一个Phone至少持续三帧数据，基于Phone的解码时也要类似限制Phone的最小持续时间，
来保证解码出来的Phone的具有明确的时长持续变化，如图\ref{fig:duration}所示。

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/chapter4/duration-crop}
\caption{基于Phone的解码}
\label{fig:duration}
\end{figure}

在中文中，音节Syllable是发音的基本单元，中文汉字发音为声韵母的组合。
因此在中文数据集中，可以使用Syllable作为基本建模单元。

但是，直接使用Mono Phone建模存在着与Mono Phone HMM状态建模相似的问题，即建模单元太少，建模不够精细。
使用与CD-State相似的概念，我们使用CD-Phone（Context Dependent Phone），给Phone加入上下文，
再通过聚类来结解决该问题。

CD-State聚类时，直接使用帧级状态对齐特征进行聚类。然而，Phone是一个有内部变化的建模单元，
在做聚类时需要考虑Phone的变化过程。Google在其CD-Phone\ucite{senior2015context}的工作中提出，
使用HMM-GMM系统中Phone的三个状态来描述Phone特征，使用三状态对齐的中值（均值）作为该Phone的特征，
如图\ref{fig:3middle}使用三状态的中值来表示Phone的聚类特征。

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{figures/chapter4/3middle-crop}
\caption{CD-Phone聚类中Phone的特征表示}
\label{fig:3middle}
\end{figure}


使用CD-Phone作为建模单元的过程如下，
\begin{enumerate}
\item 通过HMM-GMM系统得到三音素状态CD-State对齐；
\item 按如上方法进行Phone特征统计，然后使用\ref{fig:cdstate}节类似方法使用问题集和决策树方法进行聚类；
\item 将CD-State对齐转换为CD-Phone的对齐；
\item 使用CD-Phone对齐训练基于RNN的CD-Phone的声学模型。
\end{enumerate}
在解码时，与Phone的解码类似，同样需要约束CD-Phone的最小持续时长。


\section{CTC}

如前文所述，基于深度神经网络的语音识别系统需要依赖HMM-GMM系统生成的状态对齐。
语音识别本质上也是个序列标注任务，HMM方法是解决序列标注任务的一种经典方法之一。
CTC（Connectionist Temporal Classificatio）\ucite{graves2006connectionist, graves2012neural}，
于2006年由Alex Graves提出，则是解决序列标注任务的另一种经典方法。

\subsection{基本概念}

在序列标注任务中，假设字符表的大小为$L$，CTC的softmax层输出则共有$L+1$个单元。
在给定输入的情况下，其中后$L$个用于预测当前时刻分别处在这$L$个字符上的概率；
另外一个为辅助单元，称之为blank（空白），用于预测在当前时刻不产生任何输出的概率，即空白。
所以，CTC在同一时刻的输出，可以使字母表中的任意一个字符，也可以是blank。

假设训练集为$S$，给定输入序列$\textbf{x}$，其长度为$T$，其对应字符标注序列记为$textbf{l}$，
$y_k^t$表示在$t$时刻观测到字符$k$的概率，其中$k<=L$; $k=0$表示输出blank单元的概率。
则序列$\textbf{x}$的任意一个等价序列$\pi$出现的概率可以表示为：
\begin{equation}
\label{euqation:ctcpath}
{\rm{p}}(\pi | \textbf{x},S) = \prod\limits_{t = 1}^T {{\rm{y}}_{{\pi _t}}^t}
\end{equation}
其中$\pi  \in {L^{'T}}$，$L^{'T}$表示在输入序列$\textbf{x}$的标注中任意位置插入任意长度的blank，直至其总长度为$T$。
在后面介绍中，省略训练数据$S$，将$\rm{p}(\pi |\textbf{x},S)$简记为$\rm{p}(\pi|\textbf{x})$。

定义映射函数{\rm B}，表示将CTC的预测序列经过消除连续出现的字符和去除blank之后的序列。
例如${\rm B}(a - ab - ) = {\rm B}( - aa -  - abb) = abb$。
直观上看，当从连续的字符到一个新字符，或者由blank到一个非blank字符时，即认为是新的字符。
我们称之为序列等价性。这个性质使CTC可以使用未分段的数据，因为该性质无需预先知道字符出现的时刻。
这里可以看出blank的另一个作用，即允许预测序列出现两个连续相同的字符，只要这两个字符之间存在blank即可。

根据序列等价性，$\textbf{l}$的条件概率可以表示为：
\begin{equation}
\label{euqation:ctcallpath}
p({\textbf{l}}|{\textbf{x}}) = \sum\limits_{\pi  \in {{\rm B}^{ - 1}}({\textbf{l}})}^{} {p(\pi |{\textbf{x}})}
\end{equation}

理论上，CTC可以使用任意结构的RNN，但为了对当前字符做更精准的预测，一般使用双向的RNN，
这样可以有效的利用前向和后向所有历史信息。

\subsection{前向后向算法}

在给出$p({\textbf{l}}|{\textbf{x}})$ 的形式之后，
我们可以使用与HMM的前向后向算法\ref{section:probability}类似的动态规划思想来计算$p({\textbf{l}}|{\textbf{x}})$的概率。
即该问题具有最优子结构，可以通过迭代填表的方式求得。

首先，定义${{\textbf{l'}}}$表示在$\textbf{l}$的开始，结束和相邻两个字符之间插入blank后的序列，则${{\textbf{l'}}}$的长度为$2|{\textbf{l}}| + 1$。
在计算过程中，我们允许从当前一个字符直接跳到下一个字符；或者从当前字符跳到自身；或者从当前字符跳到blank。

定义${\alpha _{\rm{t}}}(s)$表示$t$时刻到达第$s$个字符的前向概率和，则
\begin{equation}
{\alpha _{\rm{t}}}(s) = P({\pi _{1:t}}:B({\pi _{1:t}}) = {{\textbf{l}}_{1:s/2}},{\pi _t} = {{l'}_s}{\rm{|}}{\textbf{x}}{\rm{) = }}\sum\limits_{\scriptstyle{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} \pi :\hfill\atop
\scriptstyle\beta ({\pi _{1:t}}) = {{\textbf{l}}_{1:s/2}}\hfill} {\prod\limits_{t' = 1}^t {y_{{\pi _{t'}}}^{t'}} }
\end{equation}
$s/2$表示去掉blank的标注。

由以上定义，标注序列$\textbf{l}$的概率可以表示为$t$时刻处在最后一个字符或者其后blank上的概率和，表明允许以最终字符或者blank结束：
\begin{equation}
p({\textbf{l}}|{\textbf{x}}) = {\alpha _T}(|{\textbf{l'}}|) + {\alpha _T}(|{\textbf{l'}}| - 1)
\end{equation}
同理，允许序列可以以第一个字符或者blank起始，则可以得到${\alpha _{\rm{t}}}(s)$的初始值：
\begin{equation}
\begin{array}{l}
{\alpha _1}(1) = y_b^1\\
{\alpha _1}(2) = y_{{l_1}}^1\\
{\alpha _1}(s) = 0,\forall s > 2
\end{array}
\end{equation}
${\alpha _{\rm{t}}}(s)$可以由${\alpha _{\rm{t-1}}}(s)$，${\alpha _{\rm{t-1}}}(s-1)$，${\alpha _{\rm{t-1}}}(s-2)$递推计算：
\begin{equation}
\label{equation:alpha}
{\alpha _{\rm{t}}}(s) = y_{{{l'}_s}}^t\left\{ \begin{array}{l}
\sum\nolimits_{i = s - 1}^s {{\alpha _{{\rm{t - 1}}}}(i){\kern 1pt} ;} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {{l'}_s} = b{\kern 1pt} {\kern 1pt} {\rm{or}}{\kern 1pt} {\kern 1pt} {{l'}_{s - 2}} = {{l'}_s}\\
\sum\nolimits_{i = s - 2}^s {{\alpha _{{\rm{t - 1}}}}(i){\kern 1pt} ;} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\rm{otherwise}}
\end{array} \right\}
\end{equation}
CTC前向跳转的一个示意如图\ref{fig:ctcforback}所示，图中给出DOG的CTC状态跳转图。
其中空心圈表示blank，实心圈表示字符，横向为时间轴，纵向为字符轴。
从左上角到右下角即为一个可能的路径。


\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/chapter4/forback-crop}
\caption{CTC前向状态跳转}
\label{fig:ctcforback}
\end{figure}

定义${\beta _{\rm{t}}}(s)$表示$t$时刻到达第$s$个字符的后向概率和，则
\begin{equation}
{\beta _{\rm{t}}}(s) = P({\pi _{{\rm{t}} + 1:T}}:B({\pi _{t:T}}) = {{\textbf{l}}_{s/2:{\rm{|}}{\textbf{l}}|}},{\pi _t} = {{l'}_s}{\rm{|}}{\textbf{x}}{\rm{) = }}\sum\limits_{\scriptstyle{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} \pi :\hfill\atop
\scriptstyle\beta ({\pi _{t:T}}) = {{\textbf{l}}_{s/2:{\rm{|}}{\textbf{l}}|}}\hfill} {\prod\limits_{t' = t + 1}^T {y_{{\pi _{t'}}}^{t'}} }
\end{equation}
同理，允许序列可以以最后一个字符或者其后的blank结束，则可以得到${\beta _{\rm{t}}}(s)$的初始值：
\begin{equation}
\begin{array}{l}
{\beta _T}(|{\textbf{l'}}|) = 1\\
{\beta _T}(|{\textbf{l'}}| - 1) = 1\\
{\beta _T}(s) = 0,\forall s < |{\textbf{l'}}| - 1
\end{array}
\end{equation}
${\beta _{\rm{t}}}(s)$的递推计算公式为：
\begin{equation}
\label{equation:beta}
{\beta _{\rm{t}}}(s) = y_{{{l'}_s}}^t\left\{ \begin{array}{l}
\sum\nolimits_{i = s}^{s + 1} {{\beta _{{\rm{t + 1}}}}(i){\kern 1pt} y_{{{l'}_s}}^{t + 1};} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {{l'}_s} = b{\kern 1pt} {\kern 1pt} {\rm{or}}{\kern 1pt} {\kern 1pt} {{l'}_{s + 2}} = {{l'}_s}\\
\sum\nolimits_{i = s}^{s + 2} {{\beta _{{\rm{t + 1}}}}(i){\kern 1pt} y_{{{l'}_s}}^{t + 1};} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\rm{otherwise}}
\end{array} \right\}
\end{equation}


实际应用中，由于计算机字长限制，上述概率的连乘运算会很快下溢。
所以该概率计算一般转到$log$域，上述递推公式\ref{equation:alpha}~\ref{equation:beta}中也存在加法，
$log$域中加法的一个有用等式是：
\begin{equation}
\ln (a + b) = \ln (a + \ln (1 + {e^{\ln b - \ln a}}))
\end{equation}
这样即解决了前向后向算法中的数值问题。

\subsection{CTC目标函数}

如上文所述，CTC的目标函数由最大似然的方法得到。并且，CTC的目标函数可导，
因此可以通过梯度的方法对CTC进行优化。
CTC的下层网络结构为RNN，同样可以通过梯度方法优化。
因此CTC在计算得到梯度后，通过反向传播的方法回传给网络，
进一步进行基于CTC损失函数的RNN网络的优化。

定义目标函数$O$表示整个训练集的负log域的概率和，则$O$可以表示为：
\begin{equation}
{\rm{O}} =  - \ln (\prod\limits_{({\textbf{x}},{\textbf{z}}) \in S} {p({\textbf{z}}|{\textbf{x}})} ) =  - \sum\limits_{({\textbf{x}},{\textbf{z}}) \in S}^{} {\ln p({\textbf{z}}|{\textbf{x}})}
\end{equation}
首先，计算$O$对网络输出的梯度:
\begin{equation}
\label{equation:o}
\frac{{\partial O}}{{\partial y_k^t}} =  - \frac{{\partial \ln p({\textbf{z}}|{\textbf{x}})}}{{\partial y_k^t}} =  - \frac{1}{{p({\textbf{z}}|{\textbf{x}})}}\frac{{\partial p({\textbf{z}}|{\textbf{x}})}}{{\partial y_k^t}}
\end{equation}
使用前向后向算法有：
\begin{equation}
{\alpha _{\rm{t}}}(s){\beta _{\rm{t}}}(s) = \sum\limits_{\scriptstyle\pi  \in {{\rm B}^{ - 1}}({\textbf{z}})\hfill\atop
\scriptstyle{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\pi _t} = {{z'}_s}\hfill} {\prod\limits_{t = 1}^T {y_{{\pi _t}}^t} }
\end{equation}
由\ref{euqation:ctcpath}有：
\begin{equation}
{\alpha _{\rm{t}}}(s){\beta _{\rm{t}}}(s) = \sum\limits_{\scriptstyle\pi  \in {{\rm B}^{ - 1}}({\textbf{z}})\hfill\atop
\scriptstyle{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\pi _t} = {{z'}_s}\hfill} {p(} \pi |{\textbf{x}})
\end{equation}
由\ref{euqation:ctcallpath}，通过全概率公式（在$t$时刻可以输出${\textbf{z}}$序列中的任意字符），所以：
\begin{equation}
\label{equation:alls}
p({\textbf{z}}|{\textbf{x}}) = \sum\limits_{s = 1}^{|{\textbf{z'}}|} {{\alpha _{\rm{t}}}(s){\beta _{\rm{t}}}(s)}
\end{equation}

为了计算对$y_k^t$的梯度，需要考虑在$t$时刻通过字符$k$的所有路径。
由于相同的字符或者blank可以在一个序列中出现多次，
因此定义$lab({\textbf{z}},k) = \{ s:{{z'}_s}{\rm{ = k\} }}$表示序列$\textbf{z}$中出现字符$k$的集合：
\begin{equation}
\frac{{\partial {\alpha _{\rm{t}}}(s){\beta _{\rm{t}}}(s)}}{{\partial y_k^t}} = \left\{ \begin{array}{l}
\frac{{{\alpha _{\rm{t}}}(s){\beta _{\rm{t}}}(s)}}{{y_k^t}},if{\kern 1pt} k{\kern 1pt} {\kern 1pt} in{\kern 1pt} {\kern 1pt} {\textbf{z'}}\\
0,{\kern 1pt} {\kern 1pt} {\kern 1pt} otherwise
\end{array} \right\}
\end{equation}
对\ref{equation:alls}求导得：
\begin{equation}
\frac{{\partial p({\textbf{z}}|{\textbf{x}})}}{{\partial y_k^t}} = \frac{1}{{y_k^t}}\sum\limits_{s \in lab({\textbf{z}},k)}^{} {{\alpha _{\rm{t}}}(s){\beta _{\rm{t}}}(s)}
\end{equation}
代入\ref{equation:o}得：
\begin{equation}
\label{equation:ctcloss}
\frac{{\partial O}}{{\partial y_k^t}} =  - \frac{1}{{p({\textbf{z}}|{\textbf{x}})y_k^t}}\sum\limits_{s \in lab({\textbf{z}},k)}^{} {{\alpha _{\rm{t}}}(s){\beta _{\rm{t}}}(s)}
\end{equation}
最后，计算对输出层$a_k^t$的梯度，$a_k^t$为softmax函数之前$t$时刻第$k$个字符单元的激励，
\begin{equation}
\label{equation:alldiff}
\frac{{\partial O}}{{\partial a_k^t}} = \sum\limits_{k'} {\frac{{\partial O}}{{\partial y_{k'}^t}}} \frac{{\partial y_{k'}^t}}{{\partial a_k^t}}
\end{equation}
根据softmax\ref{equation:softmax}函数,有
\begin{equation}
\label{equation:softmaxdiff}
\frac{{\partial y_{k'}^t}}{{\partial a_k^t}} = y_{k'}^t({\delta _{kk'}} - y_k^t)
\end{equation}
将\ref{equation:ctcloss}和\ref{equation:softmaxdiff}代入\label{equation:alldiff}得：
\begin{equation}
\frac{{\partial O}}{{\partial a_k^t}} = y_k^t - \frac{1}{{p({\textbf{z}}|{\textbf{x}})}}\sum\limits_{s \in lab({\textbf{z}},k)}^{} {{\alpha _{\rm{t}}}(s){\beta _{\rm{t}}}(s)}
\end{equation}

\subsection{CTC的特性}

经过上面的讨论，可以总结出CTC的三点特性：
\begin{enumerate}
\item \textbf{Blank}；CTC在建模中引入辅助建模单元blank，表示不作任何输出；
\item \textbf{序列等价性}；连续的相同的字符可以归约为单个字符，归约后blank被消除；
\item \textbf{尖峰（Peak）预测特性}；这是CTC在预测时的现象，其在大多数时刻上输出为blank，并且预测时输出呈尖峰状，如图\ref{fig:peak}。
\end{enumerate}

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{figures/chapter4/peak-crop}
\caption{CTC Peak预测}
\label{fig:peak}
\end{figure}

\subsection{语音识别中的应用}

语音识别任务是个天然的序列标注任务，因此可以使用CTC预测声学模型中的建模单元。
Alex Graves在2008年已经将CTC应用在TIMIT的音素识别任务上\ucite{graves2012neural}。
2015年，Miao的EESEN\ucite{miao2015eesen}在WSJ数据集上应用CTC。
同年，Google\ucite{sak2015fast}和百度\ucite{amodei2015deep}也均成功将CTC应用在大词汇量连续语音识别任务中。

在这些任务中，建模单元各有不同。
EESEN中使用Phone或者Character作为建模单元，
Google的工作中使用Phone或CD-Phone作为作为建模单元，
百度的Deep Speech 2系统在中文中使用汉字，英文中使用字母Character作为建模单元。
本文主要研究使用Phone和CD-Phone作为建模单元的CTC。

在传统的HMM语音系统中，一般使用基于WFST\ucite{mohri2004weighted}的解码器。
基于WSFT的解码器中，将HMM（H），上下文（C，Context）、词典（L，Lexicon）、语言模型（G，Grammar）通过
WFST的组合（Compose）操作构成解码图HCLG\ucite{mohri2002weighted}，然后在HCLG的WFST图上进行语音识别的解码算法。

在基于CTC的语音识别中，已经摒弃了HMM，因此需要重新构图。
将CTC的基本单元构图记为T，则T的结构如图\ref{fig:t}所示：
\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{figures/chapter4/t-crop}
\caption{CTC基本单元的WFST图}
\label{fig:t}
\end{figure}
由图中的跳转可以看出，解码时在一个CTC的基本单元内，
起始状态0可以经过任意个个blank；
从状态0输入a并输出a到达状态1，状态1上可以输入任意个a，输出为空；
状态1也可以经过空跳转<eps>到达状态2；
状态2为终结点，类似状态1，可以输入任意个blank。
通过该WFST，即可以保证CTC的一个建模单元中，前后均可以有任意个blank，
中间有任意个单元a，并且整个单元的输出为1个a，满足序列等价归约的性质。

在得到T的结构后，与HCLG类似。我们可以使用WFST的组合操作使T和更高层次的
上下文C（可选），词典L和语言模型G进行组合。
假设T中含上下文，则最终解码图WFST图S可以表示为：
\begin{equation}
{\rm{S = T}} \circ {\rm{min(det(L}} \circ {\rm{G))}}
\end{equation}
若不含上下文，S可以表示为：
\begin{equation}
{\rm{S = T}} \circ {\rm{min(det(C}} \circ {\rm{L}} \circ {\rm{G))}}
\end{equation}
其中det表示WFST的确定化操作，min表示WFST的最小化操作。

近来，Google、百度的研究\ucite{senior2015context, sak2015fast, sak2015learning, hannun2014deep, amodei2015deep}表明，
CTC不仅可以进一步提升声学建模的精度；
并且由于CTC尖峰预测的特性，CTC在主路径上的打分很强，可以远远超过竞争路径。
语音识别的解码中一般使用Beam Search\ucite{young1989token}的方法进行剪枝，
在同样的beam阈值条件下，相对于交叉熵CE的模型，
CTC解码中的竞争路径会被更快的裁剪，因此基于CTC的语音识别解码具有非常快的解码速度。
这对大幅度提升语音识别系统的响应速度和提供线上系统的吞吐量均具有重要意义。

\section{实验}

本节介绍基于Phone、CD-Phone和Syllable的声学建模实验，
并给出在这三种建模单元基础上结合CTC在中文语音识别任务上的实验结果。

\subsection{数据和模型}

以Phone、Syllable和CD-Phone为建模单元的声学模型和CTC都依赖于大量的数据，所以
本实验使用数据量更大的数据集aslp688。
aslp688\label{data:aslp688}数据集为西北工业大学音频语音与语言处理研究组标准数据集，
共688小时，语料类型为中文普通话朗读数据，共402838句，每句平均时长为6.20s，其中3484句作为交叉验证集，剩余部分全部作为训练集。
测试集使用西北工业大学音频语音与语言处理研究组标准测试集test3000，共3063句。

本实验使用语音识别工具Kaldi\ucite{povey2011kaldi}，深度神经网络使用的对齐由aslp688数据集的GMM-HMM系统产生，共有CD-State状态5389个。
GMM-HMM系统使用39维的MFCC特征，所有深度神经网络均使用40维FBank（Filter Bank）特征。

本节中，使用的网络基本结构均为CLDNN结构，含有1层CNN，2层的DNN和2层的LSTM。
其中CNN中使用40维Fbank特征，不使用差分特征，左右各拼5帧，共440维输入特征，
CNN的卷积层使用128个滤波器，其中滤波器大小为$11 \times 9$，滤波器步移为1，Max Pooling层的步长为4，步移为4，CNN的输出为1024维；
DNN隐层节点为1024；LSTM同样使用LSTMP结构，其中Cell 1024，Projection 512。

同样，CNN和DNN所用激活函数为Simoid激活函数。相邻层之间，使用Batch Normalization做输入的归一化。

本节使用的中文Phone为带调的Phone，共216个。
使用的Syllable为带调音节，音节中同样存在稀疏问题，采用绑定策略对稀疏音节绑定后共1310个音节。
CD-Phone的个数可以通过阈值调整，本节中最终的CD-Phone的聚类数为2384个。

\subsection{Phone、Syllable和CD-Phone交叉熵训练实验}

使用Phone、Syllable和CD-Phone 交叉熵训练的实验结果如表\ref{table:unit-ce}所示，
为方便性能比较，表中同样给出CD-States的DNN和CLDNN实验结果。

\begin{table}[htbp]
\centering
\caption{aslp688 Phone、Syllable和CD-Phone交叉熵训练}
\fontsize{10.5pt}{10.5pt}\song \vspace{0.5em}
\begin{tabularx}{\textwidth}{cYcc}
\toprule
编号         & 模型结构                                          & 参数量(M)           & CER           \\ \midrule
1          & DNN\_CDState5389(7DNN)                        & 7.95          & 9.23          \\
\textbf{2} & \textbf{CLDNN\_CdState5389(1CNN+2DNN+2LSTMP)} & \textbf{13.81} & \textbf{8.31} \\
3          & CLDNN\_Phone216(1CNN+2DNN+2LSTMP)             & 11.15          & 8.95          \\
4          & CLDNN\_CdPhone2384(1CNN+2DNN+2LSTMP)          & 12.26          & 11.03         \\
5          & CLDNN\_Syllable1310(1CNN+2DNN+2LSTMP)         & 11.71          & 10.66         \\ \bottomrule
\end{tabularx}
\label{table:unit-ce}
\end{table}

从表\ref{table:unit-ce}可以看出，以Phone为建模单元的交叉熵训练效果已经超过CD-States DNN的效果，
并且接近CD-States CLDNN的效果。而以Syllable和CD-Phone为建模单元的效果要略差，总体效果上Phone优于Syllable，再优于CD-Phone。

\subsection{CTC实验}

以表\ref{table:unit-ce}中的交叉熵CE模型为初始模型，使用CTC准则迭代训练，
得到表\ref{table:ctc}的实验结果，表中直接给出最优的实验结果。

\begin{table}[htbp]
\centering
\caption{aslp688 Phone、Syllable和CD-Phone CTC训练}
\fontsize{10.5pt}{10.5pt}\song \vspace{0.5em}
\begin{tabularx}{\textwidth}{cYcc}
\toprule
编号         & 模型结构                                                 & 参数量(M)           & CER           \\ \midrule
1          & 6DNN\_CDState5389(7DNN)                              & 7.95          & 9.23          \\
\textbf{2} & \textbf{CLDNN\_CdState5389(1CNN+2DNN+2LSTMP)}        & \textbf{13.81} & \textbf{8.31} \\
\textbf{3} & \textbf{CLDNN\_CTC\_Phone216(1CNN+2DNN+2LSTMP)} & \textbf{11.15} & \textbf{8.53} \\
4          & CLDNN\_CTC\_CdPhone2384(1CNN+2DNN+2LSTMP)           & 12.26          & 12.01         \\
5          & CLDNN\_CTC\_Syllable1310(1CNN+2DNN+2LSTMP)           & 11.71          & 10.34         \\ \bottomrule
\end{tabularx}
\label{table:ctc}
\end{table}

分析表\ref{table:ctc}的结果可以得到，以Phone和Syllable为建模单元的CTC训练的模型性能进一步得到提升。
基于Phone的CTC的效果已经与CD-States CLDNN的效果相当（相差0.1个百分点即认为是模型浮动），并且基于Phone的模型中由于输出层更小，
其参数比CD-State的CLDNN模型也要小一些。

 \begin{figure}[t]
  \centering
  \subfigure[CE预测]{
    \label{fig:ce-predict} %% label for first subfigure
    \includegraphics[width=0.9\textwidth]{figures/chapter4/ce-crop}}
  \hspace{1in}
  \subfigure[CTC Peak预测]{
    \label{fig:ctc-predict} %% label for second subfigure
    \includegraphics[width=0.9\textwidth]{figures/chapter4/ctc-crop}}
  \caption{CE和CTC预测比较}
  \label{fig:predict} %% label for entire figure
\end{figure}

图\ref{fig:predict}中给出交叉熵CE和CTC预测对比图。
可以看出，CE预测比较平滑，它在字符对应的特征区间（即对齐）内预测都趋向于1，
某些区间内还会存在混叠即竞争，表明该区间内在这些竞争字符上的概率都很高。
CTC的预测呈尖峰状，并且在大部分时刻上均输出blank，
在字符区间对应的特征上仅输出一个尖峰或者类尖峰，
在该区间上竞争字符的概率也要远远低于主字符。
即是说，CTC的Peak预测更鲁棒，区分性更好。


\subsection{CTC声学模型权重}

基于CTC的语音识别解码中，需要对语言模型和声学模型的权重进行调节，以期更好的识别结果。
使用表\ref{table:ctc}以Phone为建模单元的CTC模型CLDNN\_CTC\_Phone216(1CNN+2DNN+2LSTMP)为基础模型进行声学模型权重调节，
得到表\ref{table:ctc}结果。

\begin{table}[t]
\centering
\caption{CTC声学模型权重调节}
\fontsize{10.5pt}{10.5pt}\song \vspace{0.5em}
\begin{tabularx}{\textwidth}{YY}
\toprule
声学模型权重        & CER           \\ \midrule
0.50          & 9.20          \\
0.55          & 8.82          \\
0.58          & 8.71          \\
0.60          & 8.60          \\
0.63          & 8.54          \\
\textbf{0.65} & \textbf{8.53} \\
0.70          & 8.68          \\ \bottomrule
\end{tabularx}
\label{table:ctc}
\end{table}

在表\ref{table:ctc}中，当声学模型权重为0.65时，基于Phone的CTC声学模型取得最佳识别结果。
而在CD-State的语音识别解码中，最佳模型的声学模型权重仅为0.06667。
可以看出，基于Phone和CTC的声学模型权重相比CD-State的模型提高了近10倍。
这得益于CTC的Peak预测特性，提高了声学模型在识别系统中的比重。

\subsection{Blank打分调节}

基于CTC的声学模型在预测时，blank的打分很强，所以要对blank打分进行预处理，然后进一步进行识别解码。
本实验中先统计插入blank后的训练数据标注的先验，在得到CTC的打分之后，先减去各个字符的先验（log域），
然后再对blank打分进行调整（同样是减去某个值）。
同样使用表\ref{table:ctc}以Phone为建模单元的CTC模型CLDNN\_CTC\_Phone216(1CNN+2DNN+2LSTMP)为基础模型，
经过该处理，得到表\ref{table:blank}的结果。

\begin{table}[t]
\centering
\caption{CTC blank打分调节}
\fontsize{10.5pt}{10.5pt}\song \vspace{0.5em}
\begin{tabularx}{\textwidth}{YY}
\toprule
blank scale & CER           \\ \midrule
-2.0        & 8.79          \\
-1.0        & 8.54          \\
-0.5        & 8.56          \\
\textbf{0}  & \textbf{8.53} \\
0.5         & 8.62          \\
1.0         & 8.73          \\
2.0         & 9.26          \\ \bottomrule
\end{tabularx}
\label{table:blank}
\end{table}

可以看出，对blank打分进行scale操作对最终识别结果影响很大。
在该处理中，blank的先验很高，减先验相当于已经进行过scale。
所以再scale效果不是很明显，scale为0时效果最好。
如若不进行减先验处理，则scale效果会比较明显。

\subsection{CTC解码效率}

本节研究CTC的解码效率，研究CTC的Peak预测特性在语音识别解码中的作用。
本实验中，同样使用表\ref{table:ctc}的CD-States的CLDNN模型
和以Phone为建模单元的CE和CTC模型。

本实验中，使用CLDNN基础模型采用Copy模式解码。
在测试中，使用预先提好特征的测试集test3000。
对整个测试集进行解码，并统计解码的实时率RTF（Real Time Factor，解码时间与语音时长的比值）。
实验所用环境为Dell刀片式服务器，64位Ubuntu系统，24核CPU（4801MIPS），128G内存。
解码使用基于WFST的单线程解码（即每次仅解码一个测试语句）。
测试结果如表\ref{table:ctcrtf}所示。

\begin{table}[htbp]
\centering
\caption{CTC解码实时率}
\fontsize{10.5pt}{10.5pt}\song \vspace{0.5em}
\begin{tabularx}{\textwidth}{cYcc}
\toprule
编号         & 模型结构                                            & 参数量(M)           & RTF               \\ \midrule
1          & CLDNN\_CdState5389(1CNN+2DNN+2LSTMP)            & 13.81          & 0.88          \\
2          & CLDNN\_CE\_Phone216(1CNN+2DNN+2LSTMP)               & 11.15          & 1.50           \\
\textbf{3} & \textbf{CLDNN\_CTC\_Phone216(1CNN+2DNN+2LSTMP)} & \textbf{11.1567} & \textbf{0.25} \\ \bottomrule
\end{tabularx}
\label{table:ctcrtf}
\end{table}

基于深度神经网络的语音识别解码中的主要计算量有两部分，第一部分为深度神经网络的前向计算；
第二部分为识别中的Viterbi Search和Beam Search的时间。
如表\label{table:ctcrtf}所示，基于CTC的解码仅为CE模型CLDNN\_CdState5389的三分之一左右，解码速度非常快。
表中同样列出CLDNN\_CE\_Phone216模型的解码时间，其与CLDNN\_CTC\_Phone216(1CNN+2DNN+2LSTMP)模型的前向计算时间相同，
但其解码速度更慢。可能原因是其输出单元少，预测更为平滑，区分性不强。
对比该项，即可说明CTC在解码中的优势，其Peak预测特性可以更早的裁剪竞争路径，在更早的时间减小了搜索空间，
这是CTC解码相对于CE解码的核心优势。

更进一步，本节给出语音识别解码Beam Search的Beam设定对CE和CTC解码的影响。
Beam是一个阈值，在语音识别解码中，
假设某条竞争路径与目前最优路径的打分之差大于该阈值，则该竞争路径即被裁剪，以及时的减小搜索空间。
所以Beam越大，搜索空间越大，语音识别的结果越好，但同时搜索时间也越久，识别时间越长。
最终结果如表\ref{table:ctcbeam}所示，进一步表示为图\ref{fig:beam}。


\begin{table}[htbp]
\centering
\caption{CTC和CE Beam对RTF影响}
\fontsize{10.5pt}{10.5pt}\song \vspace{0.5em}
\begin{tabularx}{\textwidth}{Ycccc}
\toprule
System                                                       & 参数量(M)                   & Beam & CER   & RTF      \\ \midrule
\multirow{5}{*}{CLDNN\_CTC\_Phone216(1CNN+2DNN+2LSTMP)} & \multirow{5}{*}{11.1567} & 8.0  & 11.34 & 0.29 \\
                                                             &                          & 10.0 & 10.41 & 0.34  \\
                                                             &                          & 12.0 & 10.22 & 0.38 \\
                                                             &                          & 13.0 & 9.99  & 0.35  \\
                                                             &                          & 15.0 & 9.75  & 0.34 \\ \midrule
\multirow{5}{*}{CLDNN\_CdState5389(1CNN+2DNN+2LSTMP)}        & \multirow{5}{*}{13.8104} & 8.0  & 9.34  & 0.29 \\
                                                             &                          & 10.0 & 8.76  & 0.47 \\
                                                             &                          & 12.0 & 8.63  & 0.82 \\
                                                             &                          & 13.0 & 8.63  & 1.01   \\
                                                             &                          & 15.0 & 8.64  & 1.29  \\ \bottomrule
\end{tabularx}
\label{table:ctcbeam}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/chapter4/beam-crop}
\caption{CTC和CE Beam对RTF影响}
\label{fig:beam}
\end{figure}

分析可知，CTC解码实时率受Beam影响较小，而普通CE模型解码实时率RTF则严重依赖于beam大小。
因此，在CTC解码时，在保证RTF在可接受范围内的情况下，可以通过进一步放大Beam来提升模型精度。

\subsection{更大的数据量}

在上述实验中，以CD-Phone为建模单元的声学模型并未取得理想的效果，期望的CD-Phone的模型效果应该优于Phone。
根据CD-Phone的聚类原理，经分析可能的原因是数据量少CD-Phone聚类不够准确导致的。

\begin{table}[htbp]
\centering
\caption{2700h 口语数据集CTC声学模型}
\fontsize{10.5pt}{10.5pt}\song \vspace{0.5em}
\begin{tabularx}{\textwidth}{Ycc}
\toprule
模型                                & 建模单元数          & WER                      \\ \midrule
1CNN+9DNN(CD-State)               & 21046          & 34.9                     \\
1CNN+3LSTM(CD-Phone)              & 12167          & 32.04(8.18\%)          \\
\textbf{1CNN+3LSTM+CTC(CD-Phone)} & \textbf{12167} & \textbf{27.20(22.06\%)} \\ \bottomrule
\end{tabularx}
\label{table:bdctc}
\end{table}

因此在更大的数据集上，进行以CD-Phone为建模单元的实验。
本实验中使用百度2700小时的口语数据集，测试集为1500句。
与之前的朗读数据不同，在口语数据中，说话人说话方式更为随意、自然，因此更具挑战性。
其中CD-States共21046个，CD-Phone共12167个。
CD-State和CD-Phone均使用近万小时的数据聚类得到。
在该数据集上，得到表\ref{table:bdctc}的结果。


在该口语数据集上，CD-State的CLDNN效果并没有CNN基线系统的效果好，因此表\ref{table:bdctc}中没有给出CD-State的CLDNN的结果。
分析可知，基于CD-Phone的CE建模比基线CNN系统提升8.18\%，之后继续CTC训练，
最终比基线系统提升22.06\%，一方面说明了以CD-Phone作为基本建模单元的有效性，
另一方面说明CTC训练可以带来进一步的模型性能提升。

